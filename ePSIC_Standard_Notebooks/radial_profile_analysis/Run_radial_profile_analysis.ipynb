{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2e411c9-315c-4f9f-b844-615e03f6cbe3",
   "metadata": {},
   "source": [
    "# Atomic structure analysis with radial (azimuthal) average & variance profiles\n",
    "### Jinseok Ryu (jinseok.ryu@diamond.ac.uk)\n",
    "Only compatible with the ePSIC data processig workflow  \n",
    "Recommended to run this notebook using Python 3.10 EPSIC kernel on the jupyterhub of Diamond Light Source  \n",
    "Otherwise, it is highly probable that it will not work properly  \n",
    "[Required Python packages]  \n",
    "scipy, numpy, matplotlib, py4DSTEM, hyperspy, drca (optional for NMF, https://github.com/jinseuk56/drca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87293612-4029-443a-9b6e-78440ecb6355",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/~/script')\n",
    "\n",
    "from radial_profile_analysis import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6ec9ec-25b0-45c2-a7c0-0a50c0d550ab",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "base_dir = '/dls/e02/data/2025/mgXXXXX-X'\n",
    "subfolders = [''] # subfolder names you want to load and compare, e.g., ['sub1', 'sub2']\n",
    "final_dir = None # (optional) folder name where the data is stored in\n",
    "\n",
    "profile_length = 360 # limit the profile size\n",
    "num_load = 2 # limit the number of data for every subfolder (select files randomly)\n",
    "\n",
    "include_key = [] # keyword (datetime) for screening (to only include the specified data)\n",
    "exclude_key = [] # keyword (datetime) for screening (to exclude poor quality data)\n",
    "\n",
    "# The path of EDX data should be like this: ~/EDX/*.rpl\n",
    "run_analysis = radial_profile_analysis(base_dir, subfolders, \n",
    "                                       profile_length, num_load, final_dir,\n",
    "                                       include_key, exclude_key,\n",
    "                                       simult_edx=False, roll_axis=True, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72183487-1c7b-44ff-8920-4886d77ac379",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "# Transformation quality check (center beam alignment)\n",
    "# If there are any data of poor quality, you can exclude them in the cell above (using 'exclude_key')\n",
    "# crop=[top, bottom, left, right] -> img[top:bottom, left:right] (optional)\n",
    "run_analysis.center_beam_alignment_check(crop=[0, -1, 0, -1], \n",
    "                                         visual_title=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d093ad-0478-4acb-a7f4-8a6c7e25340f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "# Intensity integration image (BF + DF)\n",
    "run_analysis.intensity_integration_image(visual_title=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9279f2-7658-4e1e-ae3b-1b0976e2ed7b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# To simulate diffraction patterns (XRD) from prismatic structure file(s) (optional)\n",
    "str_path = [] # structure paths to compare, e.g., ['path1', 'path2']\n",
    "\n",
    "# Specify the scattering vector range -> also used in NMF decomposition and plotting\n",
    "from_unit = 0.2 # unit: 1/angstrom, it must be equal to or greater than zero\n",
    "to_unit = 0.6 # unit: 1/angstrom, it must be smaller than the maximum scattering vector\n",
    "run_analysis.basic_setup(str_path, from_unit, to_unit, \n",
    "                         broadening=0.01, fill_width=0.005) # broadening -> used to simulate diffraction patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206c6e24-2355-49c4-877d-25b126fc500d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "# Sum of radial variance and average profiles\n",
    "# profile_type: \"mean\" or \"variance\"\n",
    "# str_name=[\"structure_name_1\", \"structure_name_2\"]\n",
    "# The structure names are stored in run_analysis.int_sf.keys()\n",
    "run_analysis.sum_radial_profile(str_name=[], \n",
    "                                profile_type=\"variance\",\n",
    "                               visual_legend=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ea9db8-2862-45e5-a731-a28fbfbb7aae",
   "metadata": {},
   "source": [
    "# NMF decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a66142-8e79-4cf2-b746-59a721da37f0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Optional process\n",
    "# NMF - to optimize the number of loading vectors\n",
    "# rescale_SI=True -> divide each 3D data by its maximum value\n",
    "# max_normalize=True -> divide every profile by its maximum value\n",
    "# rescale_0_to_1=True -> rescale every profile from 0 to 1\n",
    "# Please refer to Scikit-learn, 'nmf' or 'https://github.com/jinseuk56/drca'\n",
    "# profile_type: \"mean\" or \"variance\"\n",
    "# verbose=True -> it will show the loading vectors and their corresponding coefficient maps\n",
    "# coeff_map_type: \"relative\" or \"absolute\"\n",
    "# coeff_map_type=\"absolute\" -> the colormap range of all the coefficient maps will be determined from the maximum coefficient to the minimum coefficient\n",
    "\n",
    "error_list = []\n",
    "comp_list = []\n",
    "num_comp_list = np.arange(2, 20, 2)\n",
    "\n",
    "run_analysis.NMF_decompose(num_comp_list[0], profile_type=\"variance\", \n",
    "                           rescale_SI=True, max_normalize=False, rescale_0to1=False, \n",
    "                           verbose=False, coeff_map_type=\"relative\")\n",
    "error_list.append(run_analysis.run_SI.DR.reconstruction_err_)\n",
    "comp_list.append(run_analysis.run_SI.DR.components_)\n",
    "\n",
    "for num_comp in num_comp_list[1:]:\n",
    "    print('number of components: %d'%num_comp)\n",
    "    run_analysis.run_SI.ini_DR(method=\"nmf\", num_comp=num_comp, result_visual=False, intensity_range=\"relative\")\n",
    "    error_list.append(run_analysis.run_SI.DR.reconstruction_err_)\n",
    "    comp_list.append(run_analysis.run_SI.DR.components_)\n",
    "\n",
    "# plot the errors between the original dataset and the reconstructed dataset\n",
    "# according to the number of loading vectors\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6, 4))\n",
    "ax.plot(num_comp_list, error_list, 'k-')\n",
    "ax.plot(num_comp_list, error_list, 'r*')\n",
    "ax.set_xlabel(\"Number of loading vectors\")\n",
    "ax.set_ylabel(\"Error\")\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "slope = np.gradient(error_list)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6, 4))\n",
    "ax.plot(num_comp_list, error_list, 'r-')\n",
    "ax.plot(num_comp_list, error_list, 'k*')\n",
    "ax.set_xlabel(\"Number of loading vectors\")\n",
    "ax.set_ylabel(\"Error\", color='r')\n",
    "\n",
    "ax_twin = ax.twinx()\n",
    "ax_twin.plot(num_comp_list, slope, 'b-')\n",
    "ax_twin.plot(num_comp_list, slope, 'ko')\n",
    "ax_twin.set_xticks(num_comp_list)\n",
    "ax_twin.set_ylabel(\"Gradient\", color='b')\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93cdda5c-7a08-4a3b-9a6f-f8c171e0f9d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "# NMF - to optimize the number of loading vectors\n",
    "# rescale_SI=True -> divide each 3D data by its maximum value\n",
    "# max_normalize=True -> divide every profile by its maximum value\n",
    "# rescale_0_to_1=True -> rescale every profile from 0 to 1\n",
    "# scale_crop=True -> the profiles will be cropped in a scattering vector range, otherwise in an index range\n",
    "# Please refer to Scikit-learn, 'nmf' or 'https://github.com/jinseuk56/drca'\n",
    "# profile_type: \"mean\" or \"variance\"\n",
    "# verbose=True -> it will show the loading vectors and their corresponding coefficient maps\n",
    "# coeff_map_type: \"relative\" or \"absolute\"\n",
    "# 'relative' -> color scale for each 3D data, 'absolute'-> color scale for all 3D data\n",
    "\n",
    "num_comp = 8\n",
    "run_analysis.NMF_decompose(num_comp, profile_type=\"variance\", scale_crop=True, rescale_SI=False,\n",
    "                           max_normalize=False, rescale_0to1=True, \n",
    "                           verbose=True, coeff_map_type=\"relative\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ca6fe1-9392-4f3d-9cdd-027fd0e7bb44",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "# NMF - loading vectors and their coefficient maps\n",
    "# If the number of loading vectors exceeds the number of the preset colormaps (currently five),\n",
    "# it will show the coefficient maps for only 5 loading vectors\n",
    "# lv_show [loading vector number list] -> you can choose which coefficient map to show\n",
    "# The colormap list can be accessed run_analysis.cm_rep -> new colormaps can be added\n",
    "run_analysis.NMF_result(lv_show=None, visual_title=True, title_font_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b326b14d-1f4f-4179-8b7a-84f9ca92eac0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "# NMF - show the pixels with high coefficients for each loading vector and the averaged profiles for those pixels\n",
    "# str_name=[\"structure_name_1\", \"structure_name_2\"]\n",
    "# percentile_threshold -> if 90, only the pixels with the 10% highest coefficients remain\n",
    "by_nmf_lv = run_analysis.NMF_comparison(str_name=[], percentile_threshold=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac550578-7d33-4ce0-a84b-c6df3a7cbc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "fill_width=0.001\n",
    "prominence_profile=0.0005\n",
    "\n",
    "%matplotlib inline\n",
    "fig_lv, ax_lv = plt.subplots(1, 1, figsize=(6, 4))\n",
    "for l, line in enumerate(by_nmf_lv):\n",
    "    line = line[run_analysis.range_ind[0]:run_analysis.range_ind[1]].copy()\n",
    "    peaks = find_peaks(line, prominence=prominence_profile)[0]\n",
    "    peaks = peaks * run_analysis.pixel_size_inv_Ang\n",
    "    peaks = peaks + run_analysis.from_\n",
    "    ax_lv.plot(run_analysis.x_axis, line, c=run_analysis.color_rep[l+1], label='lv %d'%(l+1))\n",
    "    \n",
    "    for ip, peak in enumerate(peaks):\n",
    "        if peak >= run_analysis.from_ and peak <= run_analysis.to_:\n",
    "            print(peak)\n",
    "            ax_lv.axvline(peak, ls=':', lw=1.5, c='r')\n",
    "            ax_lv.fill_between([peak-fill_width, peak+fill_width], \n",
    "                                  y1=np.max(line), \n",
    "                                  y2=np.min(line), \n",
    "                                  alpha=0.5, color='orange')\n",
    "            ax_lv.text(peak, np.max(line), \"%.3f\"%(peak))\n",
    "            \n",
    "ax_lv.legend()\n",
    "ax_lv.set_facecolor(\"lightgray\")\n",
    "fig_lv.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d29d42d-8c10-4f52-a398-862b2f50c6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the mean profiles of the pixels with high coefficients loading vector by loading vector\n",
    "# import hyperspy.api as hs\n",
    "# by_nmf_lv = np.asarray(by_nmf_lv)\n",
    "# print(by_nmf_lv.shape)\n",
    "# by_nmf_lv = hs.signals.Signal1D(by_nmf_lv)\n",
    "# by_nmf_lv.axes_manager[0].unit = \"loading vector\"\n",
    "# by_nmf_lv.axes_manager[1].scale = run_analysis.pixel_size_inv_Ang\n",
    "# by_nmf_lv.axes_manager[1].unit = \"1/Å\"\n",
    "# by_nmf_lv.save('%s_mean_profiles_loading_vector.hspy'%run_analysis.formatted, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36318127-567d-4ed1-8889-04f2e6b401ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "run_analysis.high_coeff_area_comparison()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a1e590-bab2-4b31-95a7-f8d41cfdb06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "run_analysis.NMF_summary_save_specific(specific_data=[''], save=False, also_dp=True, # specific_data = ['a keyword in the file name']\n",
    "                          log_scale_dp=True, also_tiff=False, \n",
    "                          fill_width=0.01, prominence_lv=0.001, \n",
    "                          prominence_profile=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79113674-4cf3-4c36-ac78-9c93adc0b5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "run_analysis.NMF_summary_save(save=False, also_tiff=False, also_dp=False, \n",
    "                              log_scale_dp=True, fill_width=0.005, \n",
    "                              prominence_lv=0.05, prominence_profile=0.005)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47dddc6b-fbde-4aac-83ee-615c7ea3439a",
   "metadata": {},
   "source": [
    "# Clustering of small areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b8929a-2c3c-4b33-bcd4-1b39db09b59c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "# Detect small areas in each mask and calculate their centroid and boundary positions\n",
    "# data_key='a keyword in the file name'\n",
    "run_analysis.effective_small_area(data_key='110236', threshold_map=\"NMF\", eps=4.0, min_sample=36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cdeb98f-baec-41c8-b88d-395cc81ba6a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "# Obtain the sum of 2D diffraction patterns for each small area\n",
    "run_analysis.small_area_investigation(save=False, also_tiff=False, virtual_4D=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd76c392-f1aa-40a0-bf5d-bdaeea2ba0e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "# Check the overlap between small areas by loading vector (if 'threshold_map=\"NMF\" above)\n",
    "run_analysis.overlap_check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10ed3f5-a30c-4863-ac11-59d1b5312bc7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "# Obtain single-phase regions for each data\n",
    "run_analysis.sum_edx(edx_from=0.2, edx_to=18.0, offset=0.18, edx_scale=0.01, visual=False)\n",
    "run_analysis.single_phase_investigation(visual=True, fig_save=False, \n",
    "                                        dp_shape=[515, 515], crop_ind=[0, 515, 0, 515],\n",
    "                                        eps=4.5, min_sample=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e503ce1-c8b3-4863-bc7d-db24ff656400",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# LV area comparison\n",
    "for i in range(len(run_analysis.subfolders)):\n",
    "    for j, adr in enumerate(run_analysis.loaded_data_path[i]):\n",
    "        data_key = os.path.dirname(run_analysis.loaded_data_path[i][j]).split(\"/\")[-1]\n",
    "        print(f'{run_analysis.subfolders[i]} | {data_key}')\n",
    "        for lv in range(run_analysis.num_comp):\n",
    "            area = (run_analysis.radial_var_split[i][j].axes_manager[0].scale**2 * \n",
    "                    run_analysis.num_lv_pixel_split[i][j][\"nominal_LV%d\"%(lv+1)])\n",
    "            print(f'LV{lv+1} area = {area} {run_analysis.radial_var_split[i][j].axes_manager[0].units}^2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fcbfce-7cc4-4f10-8a4e-ab21757fec7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pkl = {}\n",
    "save_pkl[\"boundary_lv_split\"] = run_analysis.boundary_lv_split\n",
    "save_pkl[\"centroid_lv_split\"] = run_analysis.centroid_lv_split\n",
    "save_pkl[\"clustered_lv_split\"] = run_analysis.clustered_lv_split\n",
    "save_pkl[\"pos_lv_pixel_split\"] = run_analysis.pos_lv_pixel_split\n",
    "save_pkl[\"num_lv_pixel_split\"] = run_analysis.num_lv_pixel_split\n",
    "\n",
    "import pickle\n",
    "with open('%s_single_phase.pkl'%run_analysis.formatted, 'wb') as f:\n",
    "    pickle.dump(save_pkl, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8c7571-4378-4acf-af5c-9bbbbff7252e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save the averaged diffraction patterns of single-phase areas\n",
    "for lv in range(run_analysis.num_comp):\n",
    "    hs_save = hs.signals.Signal2D(run_analysis.dp_storage['nominal_LV%d'%(lv+1)])\n",
    "    print(hs_save)\n",
    "    hs_save.axes_manager[0].unit = \"diffraction pattern\"\n",
    "    hs_save.axes_manager[1].scale = run_analysis.pixel_size_inv_Ang\n",
    "    hs_save.axes_manager[1].unit = \"1/Å\"\n",
    "    hs_save.axes_manager[2].scale = run_analysis.pixel_size_inv_Ang\n",
    "    hs_save.axes_manager[2].unit = \"1/Å\"\n",
    "    hs_save.save(\"%s_diffraction_pattern_LV%d_clustering.hspy\"%(run_analysis.formatted, lv+1), overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17662bcb-30cd-46e9-91ea-06e4ffa85101",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save the mean profiles of the pixels with high coefficients loading vector by loading vector\n",
    "by_nmf_lv = []\n",
    "for lv in range(run_analysis.num_comp):\n",
    "    by_nmf_lv.append(run_analysis.mean_rvp['nominal_LV%d'%(lv+1)]/run_analysis.num_pixel['nominal_LV%d'%(lv+1)])\n",
    "by_nmf_lv = np.asarray(by_nmf_lv)\n",
    "print(by_nmf_lv.shape)\n",
    "# by_nmf_lv_save = hs.signals.Signal1D(by_nmf_lv)\n",
    "# by_nmf_lv_save.axes_manager[0].unit = \"loading vector\"\n",
    "# by_nmf_lv_save.axes_manager[1].scale = run_analysis.pixel_size_inv_Ang\n",
    "# by_nmf_lv_save.axes_manager[1].unit = \"1/Å\"\n",
    "# by_nmf_lv_save.save('%s_mean_profiles_LV_clustering.hspy'%run_analysis.formatted, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58993a60-1508-4354-8fce-25325a2a65d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(len(run_analysis.subfolders)):\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(6, 4), dpi=300)\n",
    "    total_mean = np.mean(run_analysis.radial_var_sum_split[i], axis=0)\n",
    "    ax.plot(run_analysis.x_axis, total_mean[run_analysis.range_ind[0]:run_analysis.range_ind[1]], 'k:')\n",
    "    # ax.plot(run_analysis.x_axis, total_mean[run_analysis.range_ind[0]:run_analysis.range_ind[1]], 'k*')\n",
    "    ax.set_facecolor(\"darkgray\")\n",
    "    ax_twin = ax.twinx()\n",
    "    for lv, line in enumerate(by_nmf_lv):\n",
    "        ax_twin.plot(run_analysis.x_axis, \n",
    "               line[run_analysis.range_ind[0]:run_analysis.range_ind[1]], c=run_analysis.color_rep[lv+1], label='lv %d'%(lv+1))\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdda5b0c-7ea8-42dd-9422-131caf896256",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save the mean edx spectra of the pixels with high coefficients loading vector by loading vector\n",
    "\n",
    "run_analysis.sum_edx(edx_from=0.2, edx_to=18.0, offset=0.18, edx_scale=0.01, visual=False)\n",
    "\n",
    "edx_by_nmf_lv = []\n",
    "for lv in range(run_analysis.num_comp):\n",
    "    edx_by_nmf_lv.append(run_analysis.mean_edx['nominal_LV%d'%(lv+1)]/run_analysis.num_pixel['nominal_LV%d'%(lv+1)])\n",
    "edx_by_nmf_lv = np.asarray(edx_by_nmf_lv)\n",
    "print(edx_by_nmf_lv.shape)\n",
    "# edx_by_nmf_lv_save = hs.signals.Signal1D(edx_by_nmf_lv)\n",
    "# edx_by_nmf_lv_save.set_signal_type(\"EDS_TEM\")\n",
    "# edx_by_nmf_lv_save.axes_manager[0].name = \"loading vector\"\n",
    "# edx_by_nmf_lv_save.axes_manager[0].units = \"LV\"\n",
    "# edx_by_nmf_lv_save.axes_manager[1].scale = run_analysis.edx_scale\n",
    "# edx_by_nmf_lv_save.axes_manager[1].offset = -run_analysis.edx_offset\n",
    "# edx_by_nmf_lv_save.axes_manager[1].units = \"keV\"\n",
    "# edx_by_nmf_lv_save.axes_manager[1].name = \"Energy\"\n",
    "# print(edx_by_nmf_lv_save)\n",
    "# print(edx_by_nmf_lv_save.axes_manager)\n",
    "# edx_by_nmf_lv_save.save('%s_mean_edx_LV_clustering.hspy'%run_analysis.formatted, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb6392c-884b-494a-a86f-d08d9795fca0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "\n",
    "fig_lv, ax_lv = plt.subplots(1, 1, figsize=(12, 4), dpi=300)\n",
    "for lv, line in enumerate(edx_by_nmf_lv):\n",
    "    ax_lv.plot(run_analysis.edx_range[run_analysis.edx_range_ind[0]:run_analysis.edx_range_ind[1]], \n",
    "               line[run_analysis.edx_offset_ind[0]:run_analysis.edx_offset_ind[1]]+0.0001*lv, \n",
    "               c=run_analysis.color_rep[lv+1], label='lv %d'%(lv+1))\n",
    "# ax_lv.legend()\n",
    "ax_lv.tick_params(axis=\"both\", labelsize=15)\n",
    "ax_lv.set_facecolor(\"darkgray\")\n",
    "ax_lv.set_ylim(-0.00005, 0.0012)\n",
    "# fig_lv.suptitle(\"Compare the mean of EDX spectra between loading vectors\")\n",
    "fig_lv.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1c76f3-2492-47ef-9811-3a42c4ab35dc",
   "metadata": {},
   "source": [
    "# Concurrent EDX analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80ef247-b64b-4c09-81f3-c33a4c76ceb1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "run_analysis.edx_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb9e327-7590-4888-948e-07b686a6db90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "# energy scale: [keV]\n",
    "# EDX intensity map and sum of EDX spectra\n",
    "# The EDX calibration information is not parsed at the moment\n",
    "# So the energy range must be specified using 'edx_from', 'edx_to' and 'edx_scale'\n",
    "# The edx spectra can be shifted by changing 'offset'\n",
    "run_analysis.sum_edx(edx_from=0.2, edx_to=18.0, offset=0.2, edx_scale=0.01, visual=True, total_edx=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f818fe6-c642-43f8-9c29-28a1e456cfeb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "# sum of EDX spectra for the pixels with high NMF coefficients\n",
    "run_analysis.sum_edx(edx_from=0.2, edx_to=18.0, offset=0.2, edx_scale=0.01, visual=False)\n",
    "edx_by_nmf_lv = run_analysis.edx_classification(threshold_map='NMF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fb5bbd-0309-447d-a536-e82c92a3c7be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "%matplotlib inline\n",
    "run_analysis.sum_edx(edx_from=0.6, edx_to=18.0, offset=0.2, edx_scale=0.01, visual=False)\n",
    "fig_lv, ax_lv = plt.subplots(1, 1, figsize=(12, 4))\n",
    "for l, line in enumerate(edx_by_nmf_lv):\n",
    "    ax_lv.plot(run_analysis.edx_range[run_analysis.edx_range_ind[0]:run_analysis.edx_range_ind[1]], \n",
    "               line[run_analysis.edx_offset_ind[0]:run_analysis.edx_offset_ind[1]]+0.00005*l, c=run_analysis.color_rep[l+1], label='lv %d'%(l+1))\n",
    "ax_lv.legend()\n",
    "ax_lv.set_facecolor(\"lightgray\")\n",
    "fig_lv.suptitle(\"Compare the mean of EDX spectra between loading vectors\")\n",
    "fig_lv.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ea9e8b-a600-4209-9156-cff9c45e4e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the mean edx spectra of the pixels with high coefficients loading vector by loading vector\n",
    "# import hyperspy.api as hs\n",
    "# edx_by_nmf_lv = np.asarray(edx_by_nmf_lv)\n",
    "# print(edx_by_nmf_lv.shape)\n",
    "# edx_by_nmf_lv = hs.signals.Signal1D(edx_by_nmf_lv)\n",
    "# edx_by_nmf_lv.axes_manager[0].unit = \"loading vector\"\n",
    "# edx_by_nmf_lv.axes_manager[1].scale = run_analysis.edx_scale\n",
    "# edx_by_nmf_lv.axes_manager[1].offset = run_analysis.edx_offset\n",
    "# edx_by_nmf_lv.axes_manager[1].unit = \"keV\"\n",
    "# edx_by_nmf_lv.save('%s_mean_edx_loading_vector.hspy'%run_analysis.formatted, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4f36e4-f8d4-46ad-89a8-879e5e68a170",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# High variances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a0b90e-be8d-4ba9-8382-57a8679bc3e4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "# Peak detection\n",
    "# Please refer to SciPy 'find_peaks' for details\n",
    "# scattering vector range -> [peak_position-half_width, peak_position+half_width]\n",
    "half_width = 0.005\n",
    "run_analysis.scattering_range_of_interest(fill_width=half_width,\n",
    "                                         profile_type=\"variance\",\n",
    "                                         prominence=0.01,\n",
    "                                         height=None,\n",
    "                                         width=None,\n",
    "                                         distance=None,\n",
    "                                         threshold=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32b42ec-3308-4c46-befc-4cceeba6bb4b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "# Variance maps for the specified scattering vector range\n",
    "# Average and standard deviation of variances for the specified scattering vector range\n",
    "# Threshold maps - the pixels with high variances will be 1, otherwise 0\n",
    "### abs_threshold - > absolute threshold value\n",
    "### percentile_threshold -> if 90, only the pixels with the 10% highest variances remain\n",
    "\n",
    "# This will show the results for each peak detected in the cell above\n",
    "# The loop is not necessary\n",
    "sum_radial_list = []\n",
    "for i, peak in enumerate(run_analysis.peak_sub[run_analysis.subfolders[0]]):\n",
    "    peak_selected = peak\n",
    "    print(run_analysis.subfolders[0], \", peak No. %d - range: %.3f ~ %.3f\"%(i+1, peak-half_width, peak+half_width))\n",
    "    run_analysis.variance_map(sv_range=[peak_selected-half_width, peak_selected+half_width])\n",
    "    tmp_sum_radial = run_analysis.high_variance_map(percentile_threshold=90)\n",
    "    print(\"threshold value to determine the high variances: %.3f\"%run_analysis.abs_threshold)\n",
    "    sum_radial_list.append(tmp_sum_radial)\n",
    "\n",
    "    # optional - if you want to see the mean 2D diffraction patterns for individual data\n",
    "    # It will take a long time due to loading each 4D data\n",
    "    # run_analysis.summary_save(save=False, \n",
    "    #                           also_dp=True,\n",
    "    #                           log_scale_dp=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4431c6-2209-48c8-922f-f3704626dd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the mean profiles of the pixels with high variances peak by peak\n",
    "# import hyperspy.api as hs\n",
    "# sum_radial_list = np.asarray(sum_radial_list)\n",
    "# print(sum_radial_list.shape)\n",
    "# sum_radial_list = hs.signals.Signal1D(sum_radial_list)\n",
    "# sum_radial_list.axes_manager[0].unit = \"peak\"\n",
    "# sum_radial_list.axes_manager[1].scale = run_analysis.pixel_size_inv_Ang\n",
    "# sum_radial_list.axes_manager[1].unit = \"1/Å\"\n",
    "# sum_radial_list.save('%s_mean_profiles_by_peak.hspy'%run_analysis.formatted, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7371bd98-17c5-49d2-ae08-dd4bc4b24703",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "# Compare the mean of radial profiles\n",
    "# run_analysis.basic_setup(str_path, 0.1, 1.0, broadening=0.01) # specify the scattering vector range\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 4))\n",
    "\n",
    "# sel_peak_num = np.array([1, 2, 3]) - 1 # select a few peaks of interest\n",
    "sel_peak_num = np.arange(len(run_analysis.peak_sub[run_analysis.subfolders[0]])) # for all the peaks\n",
    "\n",
    "for i in sel_peak_num:\n",
    "    ax.plot(run_analysis.x_axis, \n",
    "               sum_radial_list[i][int(run_analysis.from_/run_analysis.pixel_size_inv_Ang):int(run_analysis.to_/run_analysis.pixel_size_inv_Ang)], \n",
    "               c=run_analysis.color_rep[i], label=\"peak No.%d\"%(i+1))\n",
    "ax.legend()\n",
    "ax.set_xlabel(\"Scattering vector (1/Å)\")\n",
    "ax.set_facecolor(\"lightgray\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) [User Conda - python_ptycho]",
   "language": "python",
   "name": "conda-env-User_Conda_-_python_ptycho-python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
